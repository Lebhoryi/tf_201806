{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NodeLookup(object):\n",
    "    def __init__(self):  \n",
    "        label_lookup_path = 'inception_model/imagenet_2012_challenge_label_map_proto.pbtxt'   \n",
    "        uid_lookup_path = 'inception_model/imagenet_synset_to_human_label_map.txt'\n",
    "        self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
    "\n",
    "    def load(self, label_lookup_path, uid_lookup_path):\n",
    "        # 加载分类字符串n********对应分类名称的文件\n",
    "        proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "        uid_to_human = {}\n",
    "        #一行一行读取数据\n",
    "        for line in proto_as_ascii_lines :\n",
    "            #去掉换行符\n",
    "            line=line.strip('\\n')\n",
    "            #按照'\\t'分割\n",
    "            parsed_items = line.split('\\t')\n",
    "            #获取分类编号\n",
    "            uid = parsed_items[0]\n",
    "            #获取分类名称\n",
    "            human_string = parsed_items[1]\n",
    "            #保存编号字符串n********与分类名称映射关系\n",
    "            uid_to_human[uid] = human_string\n",
    "\n",
    "        # 加载分类字符串n********对应分类编号1-1000的文件\n",
    "        proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
    "        node_id_to_uid = {}\n",
    "        for line in proto_as_ascii:\n",
    "            if line.startswith('  target_class:'):\n",
    "                #获取分类编号1-1000\n",
    "                target_class = int(line.split(': ')[1])\n",
    "            if line.startswith('  target_class_string:'):\n",
    "                #获取编号字符串n********\n",
    "                target_class_string = line.split(': ')[1]\n",
    "                #保存分类编号1-1000与编号字符串n********映射关系\n",
    "                node_id_to_uid[target_class] = target_class_string[1:-2]\n",
    "\n",
    "        #建立分类编号1-1000对应分类名称的映射关系\n",
    "        node_id_to_name = {}\n",
    "        for key, val in node_id_to_uid.items():\n",
    "            #获取分类名称\n",
    "            name = uid_to_human[val]\n",
    "            #建立分类编号1-1000到分类名称的映射关系\n",
    "            node_id_to_name[key] = name\n",
    "        return node_id_to_name\n",
    "\n",
    "    #传入分类编号1-1000返回分类名称\n",
    "    def id_to_string(self, node_id):\n",
    "        if node_id not in self.node_lookup:\n",
    "            return ''\n",
    "        return self.node_lookup[node_id]\n",
    "\n",
    "\n",
    "#创建一个图来存放google训练好的模型\n",
    "with tf.gfile.FastGFile('inception_model/classify_image_graph_def.pb', 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "    #遍历目录\n",
    "    for root,dirs,files in os.walk('images/'):\n",
    "        for file in files:\n",
    "            #载入图片\n",
    "            image_data = tf.gfile.FastGFile(os.path.join(root,file), 'rb').read()\n",
    "            predictions = sess.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data})#图片格式是jpg格式\n",
    "            predictions = np.squeeze(predictions)#把结果转为1维数据\n",
    "\n",
    "            #打印图片路径及名称\n",
    "            image_path = os.path.join(root,file)\n",
    "            print(image_path)\n",
    "            #显示图片\n",
    "            img=Image.open(image_path)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            #排序\n",
    "            top_k = predictions.argsort()[-5:][::-1]\n",
    "            node_lookup = NodeLookup()\n",
    "            for node_id in top_k:     \n",
    "                #获取分类名称\n",
    "                human_string = node_lookup.id_to_string(node_id)\n",
    "                #获取该分类的置信度\n",
    "                score = predictions[node_id]\n",
    "                print('%s (score = %.5f)' % (human_string, score))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
